{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contour_feature_rect\n",
    "'''\n",
    "Image Moment는 대상을 구분할 수 있는 특징\n",
    "특징으로는 Area, Perimeter, 중심점\n",
    "Image Moments는 대상을 구분한 후, 다른 대상과 구분하기 위해 대상을 설명(describe)하는 자료로 사용\n",
    "'''\n",
    "#-*- coding:utf-8 -*-\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('img/bad_rect.png')\n",
    "img1 = img.copy()\n",
    "img2 = img.copy()\n",
    "\n",
    "imgray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(imgray,127,255,0)\n",
    "#윤곽,    계층\n",
    "_, contours, _= cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cnt = contours[0]\n",
    "\n",
    "# 적용하는 숫자가 커질 수록 Point의 갯수는 감소\n",
    "\n",
    "epsilon1 = 0.01*cv2.arcLength(cnt, True)\n",
    "epsilon2 = 0.1*cv2.arcLength(cnt, True)\n",
    "\n",
    "approx1 = cv2.approxPolyDP(cnt, epsilon1, True)\n",
    "approx2 = cv2.approxPolyDP(cnt, epsilon2, True)\n",
    "\n",
    "cv2.drawContours(img, [cnt],0,(0,255,0),3) # 215개의 Point\n",
    "cv2.drawContours(img1, [approx1], 0,(0,255,0), 3) # 21개의 Point\n",
    "cv2.drawContours(img2, [approx2], 0,(0,255,0), 3) # 4개의 Point\n",
    "\n",
    "titles = ['Original', '1%', '10%']\n",
    "images = [img, img1, img2]\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(1,3,i+1), plt.title(titles[i]), plt.imshow(images[i])\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contour_property\n",
    "'''\n",
    "Contours Line의 가로 세로 비율 속성\n",
    "cv2.boundingRect() 함수를 이용하여 가로/세로 크기를 구한 후에 사용\n",
    "x, y, w, h = cv2.boundingRect(cnt)\n",
    "aspect_ratio = float(w)/h 가로세로비\n",
    "'''\n",
    "\n",
    "#-*- coding:utf-8 -*-\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('img/map.png')\n",
    "img1 = img.copy()\n",
    "\n",
    "imgray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(imgray,125,255,0)\n",
    "\n",
    "_, contours, _ = cv2.findContours(thresh, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "print(contours)\n",
    "cnt = contours[7] # 14번째가 지도의 contour line\n",
    "\n",
    "# 끝점 좌표 찾기\n",
    "leftmost = tuple(cnt[cnt[:,:,0].argmin()][0])\n",
    "rightmost = tuple(cnt[cnt[:,:,0].argmax()][0])\n",
    "topmost = tuple(cnt[cnt[:,:,1].argmin()][0])\n",
    "bottommost = tuple(cnt[cnt[:,:,1].argmax()][0])\n",
    "\n",
    "# 좌표 표시하기\n",
    "cv2.circle(img1,leftmost,20,(0,0,255),-1)\n",
    "cv2.circle(img1,rightmost,20,(0,0,255),-1)\n",
    "cv2.circle(img1,topmost,20,(0,0,255),-1)\n",
    "cv2.circle(img1,bottommost,20,(0,0,255),-1)\n",
    "\n",
    "img1 = cv2.drawContours(img1, cnt, -1, (255,0,0), 5)\n",
    "\n",
    "titles = ['Original','Result']\n",
    "images = [img, img1]\n",
    "\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1), plt.title(titles[i]), plt.imshow(images[i])\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contours _functions\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('img/star.png')\n",
    "img_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(img_gray, 127, 255,0)\n",
    "_, contours, _ = cv2.findContours(thresh,2,1)\n",
    "cnt = contours[0]\n",
    "\n",
    "hull = cv2.convexHull(cnt,returnPoints = False)\n",
    "defects = cv2.convexityDefects(cnt,hull) # [ start point, end point, farthest point, approximate distance to farthest point ]\n",
    "\n",
    "for i in range(defects.shape[0]):\n",
    "    s,e,f,d = defects[i,0]\n",
    "    start = tuple(cnt[s][0])\n",
    "    end = tuple(cnt[e][0])\n",
    "    far = tuple(cnt[f][0])\n",
    "    cv2.line(img,start,end,[0,255,0],2)\n",
    "    cv2.circle(img,far,5,[0,0,255],-1)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contours_hierarchy\n",
    "'''\n",
    "Image에는 여러개의 Contours가 존재하고, 그 사이에는 서로 포함하는 관계가 존재합니다. \n",
    "그 관계를 Contours Hierarchy라고 합니다. 이전, 이후, Parent, Child 관계를 파악할 수 있습니다. \n",
    "이런 관계를 파악하기 위해서는 cv2.findContours() 에 Contour Retrieval Mode값에 의해서 결정\n",
    "'''\n",
    "\n",
    "#-*- coding:utf-8 -*-\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('img/hierarchy.jpg')\n",
    "\n",
    "imgray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(imgray,125,255,0)\n",
    "\n",
    "_, contours, _ = cv2.findContours(thresh, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for i in range(len(contours)):\n",
    "    #각 Contour Line을 구분하기 위해서 Color Random생성\n",
    "    b = random.randrange(1,255)\n",
    "    g = random.randrange(1,255)\n",
    "    r = random.randrange(1,255)\n",
    "\n",
    "    cnt = contours[i]\n",
    "    img = cv2.drawContours(img, [cnt], -1,(b,g,r), 2)\n",
    "\n",
    "titles = ['Result']\n",
    "images = [img]\n",
    "\n",
    "for i in range(1):\n",
    "    plt.subplot(1,1,i+1), plt.title(titles[i]), plt.imshow(images[i])\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convex_hull\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('img/hand.png')\n",
    "img1 = img.copy()\n",
    "\n",
    "imgray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(imgray,127,255,0)\n",
    "\n",
    "_, contours, _ = cv2.findContours(thresh, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cnt = contours[1] # 1이 손모양 주변의 contour\n",
    "hull = cv2.convexHull(cnt)\n",
    "\n",
    "cv2.drawContours(img1, [hull], 0,(0,255,0), 3)\n",
    "\n",
    "titles = ['Original','Convex Hull']\n",
    "images = [img, img1]\n",
    "'''\n",
    "cv2.isContourConvex() 함수는 contour가 convex인지 아닌지 판단하여 True 또는 False를 Return\n",
    "convex란 contour line이 볼록하거나 최소한 평평한 것을 의미\n",
    "'''\n",
    "outline = cv2.isContourConvex(contours[0]) # 외곽선 contour line\n",
    "print(outline)\n",
    "hand = cv2.isContourConvex(contours[1]) # 손 모양 contour line\n",
    "print(hand)\n",
    "\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1), plt.title(titles[i]), plt.imshow(images[i])\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corner_goodFeaturesToTrack\n",
    "'''\n",
    "코너 검출 알고리즘은 정확하게는 트래킹(Tracking) 하기 좋은 지점(특징)을 코너\n",
    "꼭짓점은 트래킹하기 좋은 지점이 되어 다각형이나 객체의 꼭짓점을 검출하는 데 사용\n",
    "cv2.goodFeaturesToTrack\n",
    "(입력 이미지, 코너 최댓값, 코너 품질, 최소 거리, 마스크, 블록 크기, 해리스 코너 검출기 유/무, 해리스 코너 계수)\n",
    "입력 이미지는 8비트 또는 32비트의 단일 채널 이미지를 사용\n",
    "코너 최댓값은 검출할 최대 코너의 수를 제한\n",
    "코너 최댓값보다 낮은 개수만 반환\n",
    "코너 품질은 반환할 코너의 최소 품질을 설정\n",
    "코너 품질은 0.0 ~ 1.0 사이의 값으로 할당할 수 있으며, 일반적으로 0.01 ~ 0.10 사이의 값을 사용\n",
    "최소 거리는 검출된 코너들의 최소 근접 거리를 나타내며, 설정된 최소 거리 이상의 값만 검출\n",
    "마스크는 입력 이미지와 같은 차원을 사용하며, 마스크 요솟값이 0인 곳은 코너로 계산하지 않음\n",
    "블록 크기는 코너를 계산할 때, 고려하는 코너 주변 영역의 크기를 의미\n",
    "해리스 코너 검출기 유/무는 해리스 코너 검출 방법 사용 여부를 설정\n",
    "해리스 코너 계수는 해리스 알고리즘을 사용할 때 할당하며 해리스 대각합의 감도 계수를 의미\n",
    "'''\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('img/corner.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "corners = cv2.goodFeaturesToTrack(gray,25,0.01,10) # 윤곽선들의 이미지에서 코너를 검출\n",
    "corners = np.int0(corners)\n",
    "# 코너 검출 함수를 통해 corners가 반환되며, 이 배열안에 코너들의 좌표가 저장\n",
    "# 반복문을 활용해 dst에 빨간색 원으로 지점을 표시\n",
    "for i in corners:\n",
    "    x,y = i.ravel()\n",
    "    cv2.circle(img,(x,y),3,255,-1)\n",
    "\n",
    "plt.imshow(img),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corner_with_subPixel_accuracy\n",
    "'''\n",
    "빨간색의 픽셀이 cv2.cornerHarris 함수를 통해 추출한 Corner이고\n",
    "초록색의 픽셀이 cv2.cornerHarris 함수를 통해 얻은 결과를 활용해 \n",
    "cv2.cornerSubPix 함수를 적용해 좀더 정확한 Corenr의 위치를 추출한 결과\n",
    "'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('img/corner.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# find Harris corners\n",
    "gray = np.float32(gray)\n",
    "dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "dst = cv2.dilate(dst,None)\n",
    "ret, dst = cv2.threshold(dst,0.01*dst.max(),255,0)\n",
    "dst = np.uint8(dst)\n",
    "\n",
    "# find centroids\n",
    "ret, labels, stats, centroids = cv2.connectedComponentsWithStats(dst)\n",
    "\n",
    "# define the criteria to stop and refine the corners\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "corners = cv2.cornerSubPix(gray,np.float32(centroids),(5,5),(-1,-1),criteria)\n",
    "\n",
    "# Now draw them\n",
    "res = np.hstack((centroids,corners))\n",
    "res = np.int0(res)\n",
    "img[res[:,1],res[:,0]]=[0,0,255]\n",
    "img[res[:,3],res[:,2]] = [0,255,0]\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bounding_rectangle\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('img/lightning.png')\n",
    "img1 = img.copy()\n",
    "\n",
    "imgray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(imgray,127,255,0)\n",
    "\n",
    "image, contours, hierachy = cv2.findContours(thresh, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cnt = contours[1]\n",
    "\n",
    "# Straight Rectangle 대상의 Rotation은 무시한 사각형 모양입니다.\n",
    "x, y, w, h = cv2.boundingRect(cnt)\n",
    "img1 = cv2.rectangle(img1,(x,y),(x+w, y+h),(0,255,0), 3) # green\n",
    "\n",
    "# Rotated Rectangle 대상을 모두 포함하면서, 최소한의 영역을 차지하는 사각형 모양입니다.\n",
    "rect = cv2.minAreaRect(cnt)\n",
    "box = cv2.boxPoints(rect)\n",
    "box = np.int0(box)\n",
    "img1 = cv2.drawContours(img1, [box], 0, (0,0,255), 3) # blue\n",
    "\n",
    "# Minimum Enclosing Circle Contours line을 완전히 포함하는 원 중 가장 작은 원을 그릴 수 있습니다.\n",
    "(x,y), radius = cv2.minEnclosingCircle(cnt)\n",
    "center = (int(x), int(y))\n",
    "radius = int(radius)\n",
    "img1 = cv2.circle(img1, center, radius,(255,255,0),3) # yellow\n",
    "\n",
    "# Fitting an Ellipse Contours Line을 둘러싸는 타원을 그릴 수 있습니다.\n",
    "ellipse = cv2.fitEllipse(cnt)\n",
    "img1 = cv2.ellipse(img1, ellipse,(255,0,0),3) #red\n",
    "\n",
    "# Fitting a Line\n",
    "rows,cols = img.shape[:2]\n",
    "[vx,vy,x,y] = cv2.fitLine(cnt, cv2.DIST_L2,0,0.01,0.01)\n",
    "lefty = int((-x*vy/vx) + y)\n",
    "righty = int(((cols-x)*vy/vx)+y)\n",
    "img1 = cv2.line(img1,(cols-1,righty),(0,lefty),(180, 85, 162),2) # purple\n",
    "\n",
    "titles = ['Original','Result']\n",
    "images = [img, img1]\n",
    "\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1), plt.title(titles[i]), plt.imshow(images[i])\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mouse_draw\n",
    "import cv2\n",
    "import numpy as np\n",
    "# Mouse as a Paint-Brush\n",
    "drawing = False # true if mouse is pressed\n",
    "mode = True # if True, draw rectangle. Press 'm' to toggle to curve\n",
    "ix,iy = -1,-1\n",
    "\n",
    "# mouse callback function\n",
    "def draw_circle(event,x,y,flags,param):\n",
    "    global ix,iy,drawing,mode\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ix,iy = x,y\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing == True:\n",
    "            if mode == True:\n",
    "                cv2.rectangle(img,(ix,iy),(x,y),(0,255,0),-1)\n",
    "            else:\n",
    "                cv2.circle(img,(x,y),5,(0,0,255),-1)\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        if mode == True:\n",
    "            cv2.rectangle(img,(ix,iy),(x,y),(0,255,0),-1)\n",
    "        else:\n",
    "            cv2.circle(img,(x,y),5,(0,0,255),-1)\n",
    "\n",
    "img = np.zeros((512,512,3), np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "cv2.setMouseCallback('image',draw_circle)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image',img)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == ord('m'):\n",
    "        mode = not mode\n",
    "    elif k == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perspective_transformation_image\n",
    "'''\n",
    "Perspective(원근법) 변환은 직선의 성질만 유지가 되고, 선의 평행성은 유지가 되지 않는 변환\n",
    "원근법이 적용된 효과를 제거하는 예제\n",
    "'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('img/train.jpg')\n",
    "# [x,y] 좌표점을 4x2의 행렬로 작성\n",
    "# 좌표점은 좌상->좌하->우상->우하\n",
    "pts1 = np.float32([[504,1003],[243,1525],[1000,1000],[1280,1685]])\n",
    "\n",
    "# 좌표의 이동점\n",
    "pts2 = np.float32([[10,10],[10,1000],[1000,10],[1000,1000]])\n",
    "\n",
    "# pts1의 좌표에 표시. perspective 변환 후 이동 점 확인.\n",
    "cv2.circle(img, (504,1003), 20, (255,0,0),-1)\n",
    "cv2.circle(img, (243,1524), 20, (0,255,0),-1)\n",
    "cv2.circle(img, (1000,1000), 20, (0,0,255),-1)\n",
    "cv2.circle(img, (1280,1685), 20, (0,0,0),-1)\n",
    "\n",
    "M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "\n",
    "dst = cv2.warpPerspective(img, M, (1100,1100))\n",
    "\n",
    "plt.subplot(121),plt.imshow(img),plt.title('image')\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Perspective')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth_mapfromStereoImages\n",
    "'''\n",
    "포인트의 깊이는 이미지 포인트와 이를 촬영한 카메라 중심 사이의 거리 차이에 반비례한 \n",
    "이미지에서 모든 픽셀의 깊이를 얻음\n",
    "# tsukuba_l.png 파일과 tsukuba_r.png는 각각 동일한 장면에 대해 왼쪽과 오른쪽 방향에서 촬영한 이미지\n",
    "# 카메라로부터 가까운 픽셀은 밝고, 멀어질 수록 어둡게 표시\n",
    "# 결과 이미지에는 잘못된 잡음이 섞여 있는데, 이를 조정하기 위해 numDisparities와 blockSize 값을 조정해 개선\n",
    "'''\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "imgL = cv2.imread('img/Tsukuba_L.png',0)\n",
    "imgR = cv2.imread('img/Tsukuba_R.png',0)\n",
    "stereo = cv2.StereoBM_create(numDisparities=16, blockSize=15)\n",
    "disparity = stereo.compute(imgL,imgR)\n",
    "plt.imshow(disparity,'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drawKeyPoints\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('img/home.jpg')\n",
    "gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "# 그려진 특징점 각각에는 특징점의 위치, 특징점의 영향 범위에 대한 반경, \n",
    "# 그리고 회전시 특징점을 식별할 수 있는 각도값으로써의 특징점 방향\n",
    "kp = sift.detect(gray,None)\n",
    "img=cv2.drawKeypoints(gray,kp,None,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast_algorithm_for_corner_detection\n",
    "'''\n",
    "정확도를 희생하는 대신 빠른 속도로 특징점을 추출하는 방법\n",
    "특정 화소 인근의 화소값을 16개 뽑고 특정 화소의 화소값이 \n",
    "인근의 16개의 화소값에 임계치값(t)을 더한 값보다 크거나 임계치값을 뺀 값보다 \n",
    "작은 인근화소의 개수에 따라 특징점인지를 결정하는 매우 단순한 방식\n",
    "'''\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('img/corner.jpg',0)\n",
    "# Initiate FAST object with default values\n",
    "fast = cv2.FastFeatureDetector_create()\n",
    "# find and draw the keypoints\n",
    "kp = fast.detect(img,None)\n",
    "img2=cv2.drawKeypoints(img,kp,None)\n",
    "print(\"Threshold: \", fast.getThreshold())\n",
    "print(\"nonmaxSuppression: \", fast.getNonmaxSuppression())\n",
    "print(\"neighborhood: \", fast.getType())\n",
    "print(\"Total Keypoints with nonmaxSuppression: \", len(kp))\n",
    "cv2.imshow('img2', img2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast_libraryfor_approximate_nearest_neighbors\n",
    "'''\n",
    "FLANN은 Fast Library for Approximate Nearest Neighbors. \n",
    "대용량의 데이터셋과 고차원 특징점에 있어서 속도면에 최적화\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img1 = cv2.imread('img/test.jpg',0)   # queryImage\n",
    "img2 = cv2.imread('img/test_2.jpg',0) # trainImage\n",
    "# Initiate SIFT detector\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "# FLANN parameters\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks=50)   # or pass empty dictionary\n",
    "flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "matches = flann.knnMatch(des1,des2,k=2)\n",
    "# Need to draw only good matches, so create a mask\n",
    "matchesMask = [[0,0] for i in range(len(matches))]\n",
    "# ratio test as per Lowe's paper\n",
    "for i,(m,n) in enumerate(matches):\n",
    "    if m.distance < 0.3*n.distance:\n",
    "        matchesMask[i]=[1,0]\n",
    "draw_params = dict(matchColor = (0,255,0),\n",
    "                   singlePointColor = (255,0,0),\n",
    "                   matchesMask = matchesMask,\n",
    "                   flags = 0)\n",
    "img3 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,matches,None,**draw_params)\n",
    "plt.imshow(img3,)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
