{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video imshow\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('img/snoopy.avi')\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture Video from Camera\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회전된 사각형 영역이 반환된다는 점 추적 대상이 되는 영역이 커질 때 \n",
    "# 검색 결과 창도 같이 커지는 것을 확인\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "cap = cv2.VideoCapture('img/car.mp4')\n",
    "# take first frame of the video\n",
    "ret,frame = cap.read()\n",
    "# setup initial location of window\n",
    "r,h,c,w = 250,90,400,125  # simply hardcoded the values\n",
    "track_window = (c,r,w,h)\n",
    "# set up the ROI for tracking\n",
    "roi = frame[r:r+h, c:c+w]\n",
    "hsv_roi =  cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "mask = cv2.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "# Setup the termination criteria, either 10 iteration or move by atleast 1 pt\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "while(1):\n",
    "    ret ,frame = cap.read()\n",
    "    if ret == True:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "        # apply meanshift to get the new location\n",
    "        ret, track_window = cv2.CamShift(dst, track_window, term_crit)\n",
    "        # Draw it on image\n",
    "        pts = cv2.boxPoints(ret)\n",
    "        pts = np.int0(pts)\n",
    "        img2 = cv2.polylines(frame,[pts],True, 255,2)\n",
    "        cv2.imshow('img2',img2)\n",
    "        k = cv2.waitKey(60) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "        else:\n",
    "            cv2.imwrite(\"car_result.jpg\",img2)\n",
    "    else:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동영상 프로세싱\n",
    "\n",
    "import datetime\n",
    "import cv2\n",
    "\n",
    "capture = cv2.VideoCapture(\"img/snoopy.avi\")\n",
    "\n",
    "width = int(capture.get(3))  # 가로\n",
    "height = int(capture.get(4))  # 세로값 가져와서\n",
    "\n",
    " \n",
    "while (capture.isOpened):\n",
    "    ret, frame = capture.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    cv2.imshow(\"VideoFrame\", frame)\n",
    "    now = datetime.datetime.now().strftime(\"%d_%H-%M-%S\")\n",
    "    key = cv2.waitKey(33)  # 1) & 0xFF\n",
    "\n",
    "    if key == 27:  # esc 종료\n",
    "        break\n",
    "    elif key == 26:  # ctrl + z\n",
    "       cv2.IMREAD_UNCHANGED\n",
    "       cv2.imwrite(\"snoopy_result\" + \".png\", frame)\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# webcam\n",
    "import cvlib as cv\n",
    "from cvlib.object_detection import draw_bbox\n",
    "import cv2\n",
    "\n",
    "# open webcam\n",
    "webcam = cv2.VideoCapture(0)\n",
    "\n",
    "if not webcam.isOpened():\n",
    "    print(\"Could not open webcam\")\n",
    "    exit()\n",
    "    \n",
    "# loop through frames\n",
    "while webcam.isOpened():\n",
    "    # read frame from webcam \n",
    "    status, frame = webcam.read()\n",
    "    if not status:\n",
    "        break\n",
    "    # apply object detection (물체 검출)\n",
    "    bbox, label, conf = cv.detect_common_objects(frame)\n",
    "    print(bbox, label, conf)\n",
    "    # draw bounding box over detected objects (검출된 물체 가장자리에 바운딩 박스 그리기)\n",
    "    out = draw_bbox(frame, bbox, label, conf, write_conf=True)\n",
    "    # display output\n",
    "    cv2.imshow(\"Real-time object detection\", out)\n",
    "    # press \"Q\" to stop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "# release resources\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save video\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('img/video.avi',fourcc, 20.0, (640,480))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        frame = cv2.flip(frame,0)\n",
    "\n",
    "        # write the flipped frame\n",
    "        out.write(frame)\n",
    "\n",
    "        cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing_colorspaces\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture(\"./img/DigitalClock-55560.mp4\")\n",
    "\n",
    "#while(1):\n",
    "while(cap.isOpened()):\n",
    "\n",
    "    # Take each frame\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    # Convert BGR to HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # define range of blue color in HSV\n",
    "    lower_blue = np.array([110,50,50])\n",
    "    upper_blue = np.array([130,255,255])\n",
    "\n",
    "    # Threshold the HSV image to get only blue colors\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    # Bitwise-AND mask and original image\n",
    "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('res',res)\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_cv2.fastNlMeansDenoisingColoredmulti_denoising\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "cap = cv2.VideoCapture('img/car.mp4')\n",
    "\n",
    "# create a list of first 5 frames\n",
    "img = [cap.read()[1] for i in range(5)]\n",
    "\n",
    "# convert all to grayscale\n",
    "gray = [cv2.cvtColor(i, cv2.COLOR_BGR2GRAY) for i in img]\n",
    "\n",
    "# convert all to float64\n",
    "gray = [np.float64(i) for i in gray]\n",
    "\n",
    "# create a noise of variance 25\n",
    "noise = np.random.randn(*gray[1].shape)*10\n",
    "\n",
    "# Add this noise to images\n",
    "noisy = [i+noise for i in gray]\n",
    "\n",
    "# Convert back to uint8\n",
    "noisy = [np.uint8(np.clip(i,0,255)) for i in noisy]\n",
    "\n",
    "# Denoise 3rd frame considering all the 5 frames\n",
    "dst = cv2.fastNlMeansDenoisingMulti(noisy, 2, 5, None, 4, 7, 35)\n",
    "\n",
    "plt.subplot(131),plt.imshow(gray[2],'gray')\n",
    "plt.subplot(132),plt.imshow(noisy[2],'gray')\n",
    "plt.subplot(133),plt.imshow(dst,'gray')\n",
    "plt.show()\n",
    "# 첫번째 이미지는 원본 프레임이고 두번째는 잡음을 넣은 것이며 마지막은 두번째 이미지에 대한 잡음을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backgroundSubtractorGMG\n",
    "'''\n",
    "BackgroundSubtractorGMG \n",
    "정적인 배경 이미지 추정과 픽셀 당 Bayesian 분할을 조합\n",
    "'''\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('img/car.mp4')\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "#fgbg = cv2.bgsegm.createBackgroundSubtractorGMG()\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame,(400,400))\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    cv2.imshow('orig',frame)\n",
    "    cv2.imshow('frame',fgmask)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backgroundSubtractorMOG\n",
    "'''\n",
    "배경 빼냄(Background Subtraction)\n",
    "BackgroundSubtractorMOG 알고리즘으로,\n",
    "가우시안 분산값 K(K=3~5)의 홉합에 의해 각 배경 픽셀을 구성\n",
    "홉합의 가중치는 장면에서 이들 색상값들이 머무르고 있는 시간 비율\n",
    "배경으로써 판단될 수 있는 색상은 더 오랜 시간동안 변하지 않는 것\n",
    "\n",
    "cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "선택된 인자로써, 연산 인력의 길이, 가우시안 믹스쳐(혼합)의 개수, 임계값 등인데, \n",
    "이는 모두 기본값으로 설정\n",
    "비디오의 각 프레임을 얻는 루프에서 apply 매서드를 호출하여 전경에 대한 마스크를 획득 \n",
    "\n",
    "BackgroundSubtractorMOG2\n",
    "장면에서의 조도값이 변경되는 경우에도 좋은 결과를 제공하며, 그림자에 대한 처리가 가능\n",
    "또한 BackgroundSubtractorMOG와 다르게 각 픽셀마다 가우시안 분산값의 개수를 적당한 값을 선택\n",
    "이 알고리즘은 cv2.createBackgroundSubtractorMOG2() 함수로 실행 가능\n",
    "detectShadows 선택 인자를 통해 그림자에 대한 처리 여부를 결정할 수 있는데, 기본값은 True\n",
    "그림자는 마스크 결과로 회색으로 마킹\n",
    "'''\n",
    "import numpy as np\n",
    "import cv2\n",
    "cap = cv2.VideoCapture('img/car.mp4')\n",
    "#fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    cv2.imshow('frame',fgmask)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lucas-kanade_optical_flow\n",
    "'''\n",
    "Optical Flow는 카메라 또는 물체의 이동에 의해 생기는 연속된 2개의 이미지 간의 어떤 이동에 대한 패턴\n",
    "cv2.calcOpticalFlowPyrLK() 함수에 이전 프레임, 추적할 이전 포인트, 다음 프레임 등을 인자로 전달\n",
    "이 함수는 이전 프레임에서 추적할 포인트가 연속된 다음 프레임에서 추적될 경우 상태값 1을 반환하고 발견되지 못할 경우 0을 반환\n",
    "또한 추적할 포인트가 이동한 새로운 위치값도 함께 반환\n",
    "'''\n",
    "import numpy as np\n",
    "import cv2\n",
    "cap = cv2.VideoCapture('img/car.mp4')\n",
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 100,\n",
    "                       qualityLevel = 0.01,\n",
    "                       minDistance = 30,\n",
    "                       blockSize = 14)\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 0,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "# Create some random colors\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "# Take first frame and find corners in it\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "while(1):\n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # calculate optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "    # Select good points\n",
    "    good_new = p1[st==1]\n",
    "    good_old = p0[st==1]\n",
    "    # draw the tracks\n",
    "    for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "        a,b = new.ravel()\n",
    "        c,d = old.ravel()\n",
    "        mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
    "    img = cv2.add(frame,mask)\n",
    "    cv2.imshow('frame',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    # Now update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1,1,2)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense_optical_flow\n",
    "# 밀도로 보여주는 것\n",
    "# Gunner Farneback 알고리즘에 기반\n",
    "# 아래의 예제 코드는 이 알고리즘을 사용하여 Optical Flow의 밀도(Dense)를 보여줌\n",
    "import cv2\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture('img/car.mp4')\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255\n",
    "while(1):\n",
    "    ret, frame2 = cap.read()\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "    cv2.imshow('frame2',rgb)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif k == ord('s'):\n",
    "        cv2.imwrite('opticalfb.png',frame2)\n",
    "        cv2.imwrite('opticalhsv.png',rgb)\n",
    "    prvs = next\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
