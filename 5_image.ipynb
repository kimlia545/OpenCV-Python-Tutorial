{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect_gender\n",
    "# import libraries\n",
    "import cv2\n",
    "import cvlib as cv\n",
    "import numpy as np\n",
    "\n",
    "image_path = 'img/lena.jpg'\n",
    "im = cv2.imread(image_path) # 이미지 읽기\n",
    "\n",
    "\n",
    "# detect faces (얼굴 검출)\n",
    "faces, confidences = cv.detect_face(im)\n",
    "\n",
    "for face in faces:\n",
    "    (startX,startY) = face[0],face[1]\n",
    "    (endX,endY) = face[2],face[3]\n",
    "    # draw rectangle over face\n",
    "    cv2.rectangle(im, (startX,startY), (endX,endY), (0,255,0), 2) # 검출된 얼굴 위에 박스 그리기\n",
    "    face_crop = np.copy(im[startY:endY, startX:endX])\n",
    "    \n",
    "    # gender detection (성별 검출)\n",
    "    (label, confidence) = cv.detect_gender(face_crop)\n",
    "    \n",
    "    print(confidence)\n",
    "    print(label)\n",
    "    \n",
    "    idx = np.argmax(confidence)\n",
    "    label = label[idx]\n",
    "\n",
    "    label = \"{}: {:.2f}%\".format(label, confidence[idx] * 100)\n",
    "\n",
    "    Y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "\n",
    "    cv2.putText(im, label, (startX, Y),  cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.7, (0, 255, 0), 2) # 박스 위에 남자인지 여자인지 라벨과 확률 쓰기\n",
    "    \n",
    "\n",
    "cv2.imshow('result', im)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face_detectionusingHaarCascades\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "face_cascade = cv2.CascadeClassifier('data/haarcascades/haarcascade_frontface.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('data/haarcascades/haarcascade_eye.xml')\n",
    "img = cv2.imread('img/lena.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# 입력 이미지에서 얼굴을 검출하는 것입니다. 만약 얼굴을 발견하면, \n",
    "# 발견한 얼굴에 대한 위치를 Rect(x,y,w,h) 형태로 얻음\n",
    "# 이 위치를 얻었다면, 얼굴에 대한 ROI를 만들고, 이 안에서 눈을 검출\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# harris_corner_detector\n",
    "'''\n",
    "코너 검출\n",
    "cv2.cornerHarris() for this purpose. Its arguments are :\n",
    "img - Input image, it should be grayscale and float32 type.\n",
    "blockSize - It is the size of neighbourhood considered for corner detection\n",
    "ksize - Aperture parameter of Sobel derivative used.\n",
    "k - Harris detector free parameter in the equation.\n",
    "'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('img/board.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "gray = np.float32(gray)\n",
    "dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "\n",
    "#result is dilated for marking the corners, not important\n",
    "dst = cv2.dilate(dst,None)\n",
    "\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "img[dst>0.01*dst.max()]=[0,0,255]\n",
    "\n",
    "cv2.imshow('dst',img)\n",
    "if cv2.waitKey(0) & 0xff == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_backprojection\n",
    "import cv2\n",
    "import numpy as np\n",
    "roi = cv2.imread('img/test_1.jpg')\n",
    "hsv = cv2.cvtColor(roi,cv2.COLOR_BGR2HSV)\n",
    "target = cv2.imread('img/test.jpg')\n",
    "hsvt = cv2.cvtColor(target,cv2.COLOR_BGR2HSV)\n",
    "# calculating object histogram\n",
    "roihist = cv2.calcHist([hsv],[0, 1], None, [180, 256], [0, 180, 0, 256] )\n",
    "# normalize histogram and apply backprojection\n",
    "cv2.normalize(roihist,roihist,0,255,cv2.NORM_MINMAX)\n",
    "dst = cv2.calcBackProject([hsvt],[0,1],roihist,[0,180,0,256],1)\n",
    "# 2차원 히스토그램을 응용하여 이미지에서 원하는 객체만을 추출해 내는 방법\n",
    "# Now convolute with circular disc\n",
    "disc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "cv2.filter2D(dst,-1,disc,dst)\n",
    "# threshold\n",
    "ret,thresh = cv2.threshold(dst,50,255,0)\n",
    "# threshold and binary AND\n",
    "thresh = cv2.merge((thresh,thresh,thresh))\n",
    "res = cv2.bitwise_and(target,thresh)\n",
    "res = np.vstack((thresh,res))\n",
    "cv2.imshow('result', res)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram_calcHist\n",
    "'''\n",
    "# Histogram은 이미지의 밝기의 분포를 그래프로 표현\n",
    "# 히스토그램을 이용하면 이미지의 전체의 밝기 분포와 채도(색의 밝고 어두움)를 알 수 있음\n",
    "cv2.calcHist(images, channels, mask, histSize, ranges[, hist[, accumulate]])\n",
    "Parameters:\t\n",
    "image – 분석대상 이미지(uint8 or float32 type). Array형태.\n",
    "channels – 분석 채널(X축의 대상). 이미지가 graysacle이면 [0], color 이미지이면 [0],[0,1] 형태(1 : Blue, 2: Green, 3: Red)\n",
    "mask – 이미지의 분석영역. None이면 전체 영역.\n",
    "histSize – BINS 값. [256]\n",
    "ranges – Range값. [0,256]\n",
    "'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img1 = cv2.imread('img/flower.jpg',0)\n",
    "img2 = cv2.imread('img/flower2.png',0)\n",
    "\n",
    "hist1 = cv2.calcHist([img1],[0],None,[256],[0,256])\n",
    "hist2 = cv2.calcHist([img2],[0],None,[256],[0,256])\n",
    "\n",
    "plt.subplot(221),plt.imshow(img1,'gray'),plt.title('RED Line')\n",
    "plt.subplot(222),plt.imshow(img2,'gray'),plt.title('YELLOW Line')\n",
    "plt.subplot(223),plt.plot(hist1,color='r'),plt.plot(hist2,color='y')\n",
    "plt.xlim([0,256])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram_clahe\n",
    "'''\n",
    "지금까지의 처리는 이미지의 전체적인 부분에 균일화를 적용\n",
    "하지만 일반적인 이미지는 밝은 부분과 어두운 부분이 섞여 있기 때문에 \n",
    "전체에 적용하는 것은 그렇게 유용하지 않음\n",
    "contrast limit라는 값을 적용하여 이 값을 넘어가는 경우는 그 영역은 다른 영역에 균일하게 배분하여 적용\n",
    "'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "img = cv2.imread('img/hist_test2.png',0)\n",
    "\n",
    "# contrast limit가 2이고 title의 size는 8X8\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "img2 = clahe.apply(img)\n",
    "\n",
    "img = cv2.resize(img,(400,400))\n",
    "img2 = cv2.resize(img2,(400,400))\n",
    "\n",
    "dst = np.hstack((img, img2))\n",
    "cv2.imshow('img',dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram_equalization\n",
    "'''\n",
    "히스토그램 균일화(Histogram Equalization)에 대해서 알 수 있고, \n",
    "이것을 이용하여 이미지의 contrast를 향상\n",
    "이미지의 히스토그램이 특정영역에 너무 집중되어 있으면 contrast가 낮아 좋은 이미지가 아님\n",
    "전체 영역에 골고루 분포가 되어 있을 때 좋은 이미지\n",
    "특정 영역에 집중되어 있는 분포를 골고루 분포하도록 하는 작업을 Histogram Equalization\n",
    "'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "img = cv2.imread('img/hist_test.png',0)\n",
    "\n",
    "# OpenCV의 Equaliztion함수\n",
    "img2 = cv2.equalizeHist(img)\n",
    "img = cv2.resize(img,(400,400))\n",
    "img2 = cv2.resize(img2,(400,400))\n",
    "\n",
    "dst = np.hstack((img, img2))\n",
    "cv2.imshow('img',dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hough_circle_transform\n",
    "'''\n",
    "이미지에서 원을 찾을 수 있는 허프변환\n",
    "cv2.HoughCircles(image, method, dp, minDist[, circles[, param1[, param2[, minRadius[, maxRadius]]]]]) → circles\n",
    "Parameters:\t\n",
    "image – 8-bit single-channel image. grayscale image.\n",
    "method – 검출 방법. 현재는 HOUGH_GRADIENT가 있음.\n",
    "dp – dp=1이면 Input Image와 동일한 해상도.\n",
    "minDist – 검출한 원의 중심과의 최소거리. 값이 작으면 원이 아닌 것들도 검출이 되고, 너무 크면 원을 놓칠 수 있음.\n",
    "param1 – 내부적으로 사용하는 canny edge 검출기에 전달되는 Paramter\n",
    "param2 – 이 값이 작을 수록 오류가 높아짐. 크면 검출률이 낮아짐.\n",
    "minRadius – 원의 최소 반지름.\n",
    "maxRadius – 원의 최대 반지름.\n",
    "'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('img/logo.jpg',0)\n",
    "img = cv2.medianBlur(img,5)\n",
    "cimg = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "circles = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT, 1, 20,param1=50,param2=25,minRadius=0, maxRadius=0)\n",
    "\n",
    "circles = np.uint16(np.around(circles))\n",
    "\n",
    "for i in circles[0,:]:\n",
    "    cv2.circle(cimg,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "    cv2.circle(cimg,(i[0],i[1]),2,(0,0,255),3)\n",
    "\n",
    "cv2.imshow('img', cimg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hough_houghlinesP\n",
    "'''\n",
    "cv2.HoughLinesP(image, rho, theta, threshold, minLineLength, maxLineGap) → lines\n",
    "Parameters:\t\n",
    "image – 8bit, single-channel binary image, canny edge를 선 적용.\n",
    "rho – r 값의 범위 (0 ~ 1 실수)\n",
    "theta – 𝜃 값의 범위(0 ~ 180 정수)\n",
    "threshold – 만나는 점의 기준, 숫자가 작으면 많은 선이 검출되지만 정확도가 떨어지고, 숫자가 크면 정확도가 올라감.\n",
    "minLineLength – 선의 최소 길이. 이 값보다 작으면 reject.\n",
    "maxLineGap – 선과 선사이의 최대 허용간격. 이 값보다 작으며 reject.\n",
    "'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('img/dave.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,50,200,apertureSize = 3)\n",
    "minLineLength = 100\n",
    "maxLineGap = 0\n",
    "\n",
    "lines = cv2.HoughLinesP(edges,1,np.pi/360,100,minLineLength,maxLineGap)\n",
    "\n",
    "for i in range(len(lines)): #395\n",
    "    for x1,y1,x2,y2 in lines[i]:\n",
    "        cv2.line(img,(x1,y1),(x2,y2),(0,0,255),3)\n",
    "\n",
    "\n",
    "cv2.imshow('img1',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_cv2.fastNlMeansDenoisingColored_denoising\n",
    "'''\n",
    "이미지에서 잡음 제거\n",
    "\n",
    "cv2.fastNlMeansDenoising() – 그레이 이미지 하나에 대해서만 작동함\n",
    "cv2.fastNlMeansDenoisingColored() – 칼라 이미지 하나에 대해서 작동함\n",
    "cv2.fastNlMeansDenoisingMulti() – 짧은 시간 동안 찍힌 여러 개의 이미지에 대해서 작동하며 그레이 이미지여야 함\n",
    "cv2.fastNlMeansDenoisingColoredMulti() – 짧은 시간 동안 찍한 여러 개의 이미지에 대해서 작동하며 \n",
    "칼라 이미지에서 작동함\n",
    "위 함수들의 공통 인자는 다음과 같습니다.\n",
    "h : 필터 강도를 결정하는 인자. 더 높은 h 값이 잡음을 더 잘 제거하지만 잡음이 아닌 픽셀도 제거함(10이면 적당함)\n",
    "hForColorComponents : h와 동일하지만, 칼라 이미지에 대해서만 사용됨(보통 h와 같음)\n",
    "templateWindowSize : 홀수값이여야 함(7을 권장함)\n",
    "searchWindowSize : 홀수값이여야 함(21을 권장함)\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv2.imread('img/pill.png')\n",
    "dst = cv2.fastNlMeansDenoisingColored(img,None,10,10,7,21)\n",
    "plt.subplot(121),plt.imshow(img)\n",
    "plt.subplot(122),plt.imshow(dst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_thresholding\n",
    "\n",
    "'''\n",
    "cv2.threshold(src, thresh, maxval, type) → retval, dst\n",
    "Parameters:\t\n",
    "src – input image로 single-channel 이미지.(grayscale 이미지)\n",
    "thresh – 임계값\n",
    "maxval – 임계값을 넘었을 때 적용할 value\n",
    "type – thresholding type\n",
    "'''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('img/gradient.png',0)\n",
    "ret,thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "ret,thresh2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)\n",
    "ret,thresh3 = cv2.threshold(img,127,255,cv2.THRESH_TRUNC)\n",
    "ret,thresh4 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO)\n",
    "ret,thresh5 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "titles = ['Original Image','BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV']\n",
    "images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
