{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect_gender\n",
    "# import libraries\n",
    "import cv2\n",
    "import cvlib as cv\n",
    "import numpy as np\n",
    "\n",
    "image_path = 'img/lena.jpg'\n",
    "im = cv2.imread(image_path) # ì´ë¯¸ì§€ ì½ê¸°\n",
    "\n",
    "\n",
    "# detect faces (ì–¼êµ´ ê²€ì¶œ)\n",
    "faces, confidences = cv.detect_face(im)\n",
    "\n",
    "for face in faces:\n",
    "    (startX,startY) = face[0],face[1]\n",
    "    (endX,endY) = face[2],face[3]\n",
    "    # draw rectangle over face\n",
    "    cv2.rectangle(im, (startX,startY), (endX,endY), (0,255,0), 2) # ê²€ì¶œëœ ì–¼êµ´ ìœ„ì— ë°•ìŠ¤ ê·¸ë¦¬ê¸°\n",
    "    face_crop = np.copy(im[startY:endY, startX:endX])\n",
    "    \n",
    "    # gender detection (ì„±ë³„ ê²€ì¶œ)\n",
    "    (label, confidence) = cv.detect_gender(face_crop)\n",
    "    \n",
    "    print(confidence)\n",
    "    print(label)\n",
    "    \n",
    "    idx = np.argmax(confidence)\n",
    "    label = label[idx]\n",
    "\n",
    "    label = \"{}: {:.2f}%\".format(label, confidence[idx] * 100)\n",
    "\n",
    "    Y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "\n",
    "    cv2.putText(im, label, (startX, Y),  cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.7, (0, 255, 0), 2) # ë°•ìŠ¤ ìœ„ì— ë‚¨ìì¸ì§€ ì—¬ìì¸ì§€ ë¼ë²¨ê³¼ í™•ë¥  ì“°ê¸°\n",
    "    \n",
    "\n",
    "cv2.imshow('result', im)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face_detectionusingHaarCascades\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "face_cascade = cv2.CascadeClassifier('data/haarcascades/haarcascade_frontface.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('data/haarcascades/haarcascade_eye.xml')\n",
    "img = cv2.imread('img/lena.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# ì…ë ¥ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ê²€ì¶œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë§Œì•½ ì–¼êµ´ì„ ë°œê²¬í•˜ë©´, \n",
    "# ë°œê²¬í•œ ì–¼êµ´ì— ëŒ€í•œ ìœ„ì¹˜ë¥¼ Rect(x,y,w,h) í˜•íƒœë¡œ ì–»ìŒ\n",
    "# ì´ ìœ„ì¹˜ë¥¼ ì–»ì—ˆë‹¤ë©´, ì–¼êµ´ì— ëŒ€í•œ ROIë¥¼ ë§Œë“¤ê³ , ì´ ì•ˆì—ì„œ ëˆˆì„ ê²€ì¶œ\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# harris_corner_detector\n",
    "'''\n",
    "ì½”ë„ˆ ê²€ì¶œ\n",
    "cv2.cornerHarris() for this purpose. Its arguments are :\n",
    "img - Input image, it should be grayscale and float32 type.\n",
    "blockSize - It is the size of neighbourhood considered for corner detection\n",
    "ksize - Aperture parameter of Sobel derivative used.\n",
    "k - Harris detector free parameter in the equation.\n",
    "'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('img/board.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "gray = np.float32(gray)\n",
    "dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "\n",
    "#result is dilated for marking the corners, not important\n",
    "dst = cv2.dilate(dst,None)\n",
    "\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "img[dst>0.01*dst.max()]=[0,0,255]\n",
    "\n",
    "cv2.imshow('dst',img)\n",
    "if cv2.waitKey(0) & 0xff == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_backprojection\n",
    "import cv2\n",
    "import numpy as np\n",
    "roi = cv2.imread('img/test_1.jpg')\n",
    "hsv = cv2.cvtColor(roi,cv2.COLOR_BGR2HSV)\n",
    "target = cv2.imread('img/test.jpg')\n",
    "hsvt = cv2.cvtColor(target,cv2.COLOR_BGR2HSV)\n",
    "# calculating object histogram\n",
    "roihist = cv2.calcHist([hsv],[0, 1], None, [180, 256], [0, 180, 0, 256] )\n",
    "# normalize histogram and apply backprojection\n",
    "cv2.normalize(roihist,roihist,0,255,cv2.NORM_MINMAX)\n",
    "dst = cv2.calcBackProject([hsvt],[0,1],roihist,[0,180,0,256],1)\n",
    "# 2ì°¨ì› íˆìŠ¤í† ê·¸ë¨ì„ ì‘ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ ì›í•˜ëŠ” ê°ì²´ë§Œì„ ì¶”ì¶œí•´ ë‚´ëŠ” ë°©ë²•\n",
    "# Now convolute with circular disc\n",
    "disc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "cv2.filter2D(dst,-1,disc,dst)\n",
    "# threshold\n",
    "ret,thresh = cv2.threshold(dst,50,255,0)\n",
    "# threshold and binary AND\n",
    "thresh = cv2.merge((thresh,thresh,thresh))\n",
    "res = cv2.bitwise_and(target,thresh)\n",
    "res = np.vstack((thresh,res))\n",
    "cv2.imshow('result', res)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram_calcHist\n",
    "'''\n",
    "# Histogramì€ ì´ë¯¸ì§€ì˜ ë°ê¸°ì˜ ë¶„í¬ë¥¼ ê·¸ë˜í”„ë¡œ í‘œí˜„\n",
    "# íˆìŠ¤í† ê·¸ë¨ì„ ì´ìš©í•˜ë©´ ì´ë¯¸ì§€ì˜ ì „ì²´ì˜ ë°ê¸° ë¶„í¬ì™€ ì±„ë„(ìƒ‰ì˜ ë°ê³  ì–´ë‘ì›€)ë¥¼ ì•Œ ìˆ˜ ìˆìŒ\n",
    "cv2.calcHist(images, channels, mask, histSize, ranges[, hist[, accumulate]])\n",
    "Parameters:\t\n",
    "image â€“ ë¶„ì„ëŒ€ìƒ ì´ë¯¸ì§€(uint8 or float32 type). Arrayí˜•íƒœ.\n",
    "channels â€“ ë¶„ì„ ì±„ë„(Xì¶•ì˜ ëŒ€ìƒ). ì´ë¯¸ì§€ê°€ graysacleì´ë©´ [0], color ì´ë¯¸ì§€ì´ë©´ [0],[0,1] í˜•íƒœ(1 : Blue, 2: Green, 3: Red)\n",
    "mask â€“ ì´ë¯¸ì§€ì˜ ë¶„ì„ì˜ì—­. Noneì´ë©´ ì „ì²´ ì˜ì—­.\n",
    "histSize â€“ BINS ê°’. [256]\n",
    "ranges â€“ Rangeê°’. [0,256]\n",
    "'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img1 = cv2.imread('img/flower.jpg',0)\n",
    "img2 = cv2.imread('img/flower2.png',0)\n",
    "\n",
    "hist1 = cv2.calcHist([img1],[0],None,[256],[0,256])\n",
    "hist2 = cv2.calcHist([img2],[0],None,[256],[0,256])\n",
    "\n",
    "plt.subplot(221),plt.imshow(img1,'gray'),plt.title('RED Line')\n",
    "plt.subplot(222),plt.imshow(img2,'gray'),plt.title('YELLOW Line')\n",
    "plt.subplot(223),plt.plot(hist1,color='r'),plt.plot(hist2,color='y')\n",
    "plt.xlim([0,256])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram_clahe\n",
    "'''\n",
    "ì§€ê¸ˆê¹Œì§€ì˜ ì²˜ë¦¬ëŠ” ì´ë¯¸ì§€ì˜ ì „ì²´ì ì¸ ë¶€ë¶„ì— ê· ì¼í™”ë¥¼ ì ìš©\n",
    "í•˜ì§€ë§Œ ì¼ë°˜ì ì¸ ì´ë¯¸ì§€ëŠ” ë°ì€ ë¶€ë¶„ê³¼ ì–´ë‘ìš´ ë¶€ë¶„ì´ ì„ì—¬ ìˆê¸° ë•Œë¬¸ì— \n",
    "ì „ì²´ì— ì ìš©í•˜ëŠ” ê²ƒì€ ê·¸ë ‡ê²Œ ìœ ìš©í•˜ì§€ ì•ŠìŒ\n",
    "contrast limitë¼ëŠ” ê°’ì„ ì ìš©í•˜ì—¬ ì´ ê°’ì„ ë„˜ì–´ê°€ëŠ” ê²½ìš°ëŠ” ê·¸ ì˜ì—­ì€ ë‹¤ë¥¸ ì˜ì—­ì— ê· ì¼í•˜ê²Œ ë°°ë¶„í•˜ì—¬ ì ìš©\n",
    "'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "img = cv2.imread('img/hist_test2.png',0)\n",
    "\n",
    "# contrast limitê°€ 2ì´ê³  titleì˜ sizeëŠ” 8X8\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "img2 = clahe.apply(img)\n",
    "\n",
    "img = cv2.resize(img,(400,400))\n",
    "img2 = cv2.resize(img2,(400,400))\n",
    "\n",
    "dst = np.hstack((img, img2))\n",
    "cv2.imshow('img',dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram_equalization\n",
    "'''\n",
    "íˆìŠ¤í† ê·¸ë¨ ê· ì¼í™”(Histogram Equalization)ì— ëŒ€í•´ì„œ ì•Œ ìˆ˜ ìˆê³ , \n",
    "ì´ê²ƒì„ ì´ìš©í•˜ì—¬ ì´ë¯¸ì§€ì˜ contrastë¥¼ í–¥ìƒ\n",
    "ì´ë¯¸ì§€ì˜ íˆìŠ¤í† ê·¸ë¨ì´ íŠ¹ì •ì˜ì—­ì— ë„ˆë¬´ ì§‘ì¤‘ë˜ì–´ ìˆìœ¼ë©´ contrastê°€ ë‚®ì•„ ì¢‹ì€ ì´ë¯¸ì§€ê°€ ì•„ë‹˜\n",
    "ì „ì²´ ì˜ì—­ì— ê³¨ê³ ë£¨ ë¶„í¬ê°€ ë˜ì–´ ìˆì„ ë•Œ ì¢‹ì€ ì´ë¯¸ì§€\n",
    "íŠ¹ì • ì˜ì—­ì— ì§‘ì¤‘ë˜ì–´ ìˆëŠ” ë¶„í¬ë¥¼ ê³¨ê³ ë£¨ ë¶„í¬í•˜ë„ë¡ í•˜ëŠ” ì‘ì—…ì„ Histogram Equalization\n",
    "'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "img = cv2.imread('img/hist_test.png',0)\n",
    "\n",
    "# OpenCVì˜ Equaliztioní•¨ìˆ˜\n",
    "img2 = cv2.equalizeHist(img)\n",
    "img = cv2.resize(img,(400,400))\n",
    "img2 = cv2.resize(img2,(400,400))\n",
    "\n",
    "dst = np.hstack((img, img2))\n",
    "cv2.imshow('img',dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hough_circle_transform\n",
    "'''\n",
    "ì´ë¯¸ì§€ì—ì„œ ì›ì„ ì°¾ì„ ìˆ˜ ìˆëŠ” í—ˆí”„ë³€í™˜\n",
    "cv2.HoughCircles(image, method, dp, minDist[, circles[, param1[, param2[, minRadius[, maxRadius]]]]]) â†’ circles\n",
    "Parameters:\t\n",
    "image â€“ 8-bit single-channel image. grayscale image.\n",
    "method â€“ ê²€ì¶œ ë°©ë²•. í˜„ì¬ëŠ” HOUGH_GRADIENTê°€ ìˆìŒ.\n",
    "dp â€“ dp=1ì´ë©´ Input Imageì™€ ë™ì¼í•œ í•´ìƒë„.\n",
    "minDist â€“ ê²€ì¶œí•œ ì›ì˜ ì¤‘ì‹¬ê³¼ì˜ ìµœì†Œê±°ë¦¬. ê°’ì´ ì‘ìœ¼ë©´ ì›ì´ ì•„ë‹Œ ê²ƒë“¤ë„ ê²€ì¶œì´ ë˜ê³ , ë„ˆë¬´ í¬ë©´ ì›ì„ ë†“ì¹  ìˆ˜ ìˆìŒ.\n",
    "param1 â€“ ë‚´ë¶€ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” canny edge ê²€ì¶œê¸°ì— ì „ë‹¬ë˜ëŠ” Paramter\n",
    "param2 â€“ ì´ ê°’ì´ ì‘ì„ ìˆ˜ë¡ ì˜¤ë¥˜ê°€ ë†’ì•„ì§. í¬ë©´ ê²€ì¶œë¥ ì´ ë‚®ì•„ì§.\n",
    "minRadius â€“ ì›ì˜ ìµœì†Œ ë°˜ì§€ë¦„.\n",
    "maxRadius â€“ ì›ì˜ ìµœëŒ€ ë°˜ì§€ë¦„.\n",
    "'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('img/logo.jpg',0)\n",
    "img = cv2.medianBlur(img,5)\n",
    "cimg = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "circles = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT, 1, 20,param1=50,param2=25,minRadius=0, maxRadius=0)\n",
    "\n",
    "circles = np.uint16(np.around(circles))\n",
    "\n",
    "for i in circles[0,:]:\n",
    "    cv2.circle(cimg,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "    cv2.circle(cimg,(i[0],i[1]),2,(0,0,255),3)\n",
    "\n",
    "cv2.imshow('img', cimg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hough_houghlinesP\n",
    "'''\n",
    "cv2.HoughLinesP(image, rho, theta, threshold, minLineLength, maxLineGap) â†’ lines\n",
    "Parameters:\t\n",
    "image â€“ 8bit, single-channel binary image, canny edgeë¥¼ ì„  ì ìš©.\n",
    "rho â€“ r ê°’ì˜ ë²”ìœ„ (0 ~ 1 ì‹¤ìˆ˜)\n",
    "theta â€“ ğœƒ ê°’ì˜ ë²”ìœ„(0 ~ 180 ì •ìˆ˜)\n",
    "threshold â€“ ë§Œë‚˜ëŠ” ì ì˜ ê¸°ì¤€, ìˆ«ìê°€ ì‘ìœ¼ë©´ ë§ì€ ì„ ì´ ê²€ì¶œë˜ì§€ë§Œ ì •í™•ë„ê°€ ë–¨ì–´ì§€ê³ , ìˆ«ìê°€ í¬ë©´ ì •í™•ë„ê°€ ì˜¬ë¼ê°.\n",
    "minLineLength â€“ ì„ ì˜ ìµœì†Œ ê¸¸ì´. ì´ ê°’ë³´ë‹¤ ì‘ìœ¼ë©´ reject.\n",
    "maxLineGap â€“ ì„ ê³¼ ì„ ì‚¬ì´ì˜ ìµœëŒ€ í—ˆìš©ê°„ê²©. ì´ ê°’ë³´ë‹¤ ì‘ìœ¼ë©° reject.\n",
    "'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('img/dave.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,50,200,apertureSize = 3)\n",
    "minLineLength = 100\n",
    "maxLineGap = 0\n",
    "\n",
    "lines = cv2.HoughLinesP(edges,1,np.pi/360,100,minLineLength,maxLineGap)\n",
    "\n",
    "for i in range(len(lines)): #395\n",
    "    for x1,y1,x2,y2 in lines[i]:\n",
    "        cv2.line(img,(x1,y1),(x2,y2),(0,0,255),3)\n",
    "\n",
    "\n",
    "cv2.imshow('img1',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_cv2.fastNlMeansDenoisingColored_denoising\n",
    "'''\n",
    "ì´ë¯¸ì§€ì—ì„œ ì¡ìŒ ì œê±°\n",
    "\n",
    "cv2.fastNlMeansDenoising() â€“ ê·¸ë ˆì´ ì´ë¯¸ì§€ í•˜ë‚˜ì— ëŒ€í•´ì„œë§Œ ì‘ë™í•¨\n",
    "cv2.fastNlMeansDenoisingColored() â€“ ì¹¼ë¼ ì´ë¯¸ì§€ í•˜ë‚˜ì— ëŒ€í•´ì„œ ì‘ë™í•¨\n",
    "cv2.fastNlMeansDenoisingMulti() â€“ ì§§ì€ ì‹œê°„ ë™ì•ˆ ì°íŒ ì—¬ëŸ¬ ê°œì˜ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œ ì‘ë™í•˜ë©° ê·¸ë ˆì´ ì´ë¯¸ì§€ì—¬ì•¼ í•¨\n",
    "cv2.fastNlMeansDenoisingColoredMulti() â€“ ì§§ì€ ì‹œê°„ ë™ì•ˆ ì°í•œ ì—¬ëŸ¬ ê°œì˜ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œ ì‘ë™í•˜ë©° \n",
    "ì¹¼ë¼ ì´ë¯¸ì§€ì—ì„œ ì‘ë™í•¨\n",
    "ìœ„ í•¨ìˆ˜ë“¤ì˜ ê³µí†µ ì¸ìëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
    "h : í•„í„° ê°•ë„ë¥¼ ê²°ì •í•˜ëŠ” ì¸ì. ë” ë†’ì€ h ê°’ì´ ì¡ìŒì„ ë” ì˜ ì œê±°í•˜ì§€ë§Œ ì¡ìŒì´ ì•„ë‹Œ í”½ì…€ë„ ì œê±°í•¨(10ì´ë©´ ì ë‹¹í•¨)\n",
    "hForColorComponents : hì™€ ë™ì¼í•˜ì§€ë§Œ, ì¹¼ë¼ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œë§Œ ì‚¬ìš©ë¨(ë³´í†µ hì™€ ê°™ìŒ)\n",
    "templateWindowSize : í™€ìˆ˜ê°’ì´ì—¬ì•¼ í•¨(7ì„ ê¶Œì¥í•¨)\n",
    "searchWindowSize : í™€ìˆ˜ê°’ì´ì—¬ì•¼ í•¨(21ì„ ê¶Œì¥í•¨)\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv2.imread('img/pill.png')\n",
    "dst = cv2.fastNlMeansDenoisingColored(img,None,10,10,7,21)\n",
    "plt.subplot(121),plt.imshow(img)\n",
    "plt.subplot(122),plt.imshow(dst)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_thresholding\n",
    "\n",
    "'''\n",
    "cv2.threshold(src, thresh, maxval, type) â†’ retval, dst\n",
    "Parameters:\t\n",
    "src â€“ input imageë¡œ single-channel ì´ë¯¸ì§€.(grayscale ì´ë¯¸ì§€)\n",
    "thresh â€“ ì„ê³„ê°’\n",
    "maxval â€“ ì„ê³„ê°’ì„ ë„˜ì—ˆì„ ë•Œ ì ìš©í•  value\n",
    "type â€“ thresholding type\n",
    "'''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('img/gradient.png',0)\n",
    "ret,thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "ret,thresh2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)\n",
    "ret,thresh3 = cv2.threshold(img,127,255,cv2.THRESH_TRUNC)\n",
    "ret,thresh4 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO)\n",
    "ret,thresh5 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "titles = ['Original Image','BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV']\n",
    "images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
