{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaptive_thresholding\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('img/snoopy.jpg',0)\n",
    "img = cv2.medianBlur(img,5)\n",
    "\n",
    "ret,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "th2 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "            cv2.THRESH_BINARY,11,2)\n",
    "th3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "titles = ['Original Image', 'Global Thresholding (v = 127)',\n",
    "            'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\n",
    "images = [img, th1, th2, th3]\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_color\n",
    "'''\n",
    "k-Nearest Neighbour(kNN) 알고리즘\n",
    "'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "trainData = np.random.randint(0,100,(25,2)).astype(np.float32)\n",
    "\n",
    "response = np.random.randint(0,2,(25,1)).astype(np.float32)\n",
    "\n",
    "red = trainData[response.ravel() == 0] #red는 0 class로 분류\n",
    "plt.scatter(red[:,0],red[:,1], 80,'r','^')\n",
    "\n",
    "blue = trainData[response.ravel() == 1] #blue는 1 Class분류\n",
    "plt.scatter(blue[:,0], blue[:,1], 80, 'b', 's')\n",
    "\n",
    "newcomer = np.random.randint(0,100,(1,2)).astype(np.float32)\n",
    "plt.scatter(newcomer[:,0], newcomer[:,1],80,'g', 'o')\n",
    "\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(trainData, cv2.ml.ROW_SAMPLE, response)\n",
    "ret, results, neighbours, dist = knn.findNearest(newcomer, 3) #k 값을 3으로 설정\n",
    "\n",
    "print (\"result : \", results)\n",
    "print (\"neighbours :\", neighbours)\n",
    "print (\"distance: \", dist)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplot\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('img/snoopy.jpg',0)\n",
    "plt.imshow(img, cmap = 'gray', interpolation = 'bicubic')\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplot2\n",
    "\n",
    "'''\n",
    "openCV는 BGR로 사용하지만, Matplotlib는 RGB로 이미지를 보여줌\n",
    "즉 결과 값은 3차원 배열의 값중 첫번째와 세번째 배열값을 서로 바꿔야 함\n",
    "'''\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt # as는 alias 적용시 사용\n",
    "\n",
    "img = cv2.imread('img/snoopy.jpg', cv2.IMREAD_COLOR)\n",
    "\n",
    "b, g, r = cv2.split(img)   # img파일을 b,g,r로 분리\n",
    "img2 = cv2.merge([r,g,b]) # b, r을 바꿔서 Merge\n",
    "\n",
    "plt.imshow(img2)\n",
    "plt.xticks([]) # x축 눈금\n",
    "plt.yticks([]) # y축 눈금\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template_matching\n",
    "'''\n",
    "템플릿 매칭은 원본 이미지에서 특정 이미지를 찾는 방법\n",
    "cv2.TM_SQDIFF , cv2.TM_SQDIFF_NORMED 은 가장 어두운 곳이 매칭지점이고, 나머지는 가장 밝은 곳이 매칭 지정\n",
    "'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('img/test.jpg',0)\n",
    "img2 = img.copy()\n",
    "template = cv2.imread('img/test_2.jpg',0)\n",
    "\n",
    "# template 이미지의 가로/세로\n",
    "w,h = template.shape[::-1]\n",
    "\n",
    "# Template Match Method\n",
    "methods = ['cv2.TM_CCOEFF','cv2.TM_CCOEFF_NORMED','cv2.TM_CCORR','cv2.TM_CCORR_NORMED','cv2.TM_SQDIFF','cv2.TM_SQDIFF_NORMED']\n",
    "\n",
    "for meth in methods:\n",
    "    img = img2.copy()\n",
    "    method = eval(meth)\n",
    "\n",
    "    res = cv2.matchTemplate(img,template,method)\n",
    "    min_val,max_val,min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "        top_left = min_loc\n",
    "    else:\n",
    "        top_left = max_loc\n",
    "\n",
    "    bottom_right = (top_left[0]+w,top_left[1]+h)\n",
    "    cv2.rectangle(img,top_left,bottom_right,255,5)\n",
    "\n",
    "    plt.subplot(121),plt.title(meth),plt.imshow(res,cmap='gray'),plt.yticks([]),plt.xticks([])\n",
    "    plt.subplot(122),plt.imshow(img,cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oriented_fast_and_rotated_BRIEF\n",
    "'''\n",
    "ORB는 저전력의 단말기에서도 잘작동하며 파노라마 이미지 생성을 위한 이미지 붙이기 등의 기능에 적합\n",
    "FAST 알고리즘을 사용해 특징점을 검출\n",
    "FAST 알고리즘은 코너뿐만 아니라 가장자리에도 반응하는 문제점으로 인해 해리스 코너 검출 알고리즘을 적용해 최상위 특징점만 추출\n",
    "이 과정에서 이미지 피라미드를 구성해 스케일 공간 검색을 수행\n",
    "'''\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('img/corner.jpg')\n",
    "imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img2 = None\n",
    "orb = cv2.ORB_create()\n",
    "kp, des = orb.detectAndCompute(img, None)\n",
    "img2 = cv2.drawKeypoints(img, kp, img2, (255,0,0), flags=0)\n",
    "cv2.imshow('img2', img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
